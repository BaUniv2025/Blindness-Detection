import streamlit as st
import torch
from torchvision import transforms
from PIL import Image
import cv2
import numpy as np

from utils.model import BinaryCNN
from utils.visualisation import generate_gradcam, draw_aggressive_merged_boxes


# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(page_title="–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–µ—Ç–∏–Ω–æ–ø–∞—Ç–∏–∏", layout="wide")
st.title("üß† –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≥–ª–∞–∑–Ω–æ–≥–æ –¥–Ω–∞: –ó–¥–æ—Ä–æ–≤ / –î–∏–∞–±–µ—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ—Ç–∏–Ω–æ–ø–∞—Ç–∏—è")

# --- –ö–ª–∞—Å—Å—ã ---
class_names = ["–ó–¥–æ—Ä–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ", "–î–∏–∞–±–µ—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ—Ç–∏–Ω–æ–ø–∞—Ç–∏—è"]

# --- –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ---
device = torch.device(
    "mps" if torch.backends.mps.is_available() else
    "cuda" if torch.cuda.is_available() else
    "cpu"
)

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ---


@st.cache_resource
def load_model():
    model = BinaryCNN()
    model.load_state_dict(torch.load("data/model1.pth", map_location=device))
    model.to(device)
    model.eval()
    return model


model = load_model()

# --- –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ---
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# --- –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–≤—É—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–æ–∫ –æ –±–æ–∫ —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –≤—ã—Å–æ—Ç–æ–π ---


def show_side_by_side(left_img, right_img, captions=("–û—Ä–∏–≥–∏–Ω–∞–ª", "–° –∑–æ–Ω–∞–º–∏ –≤–Ω–∏–º–∞–Ω–∏—è"), height=400):
    col1, col2 = st.columns(2)

    def resize_by_height(img, target_h):
        h, w = img.shape[:2]
        scale = target_h / h
        new_w = int(w * scale)
        return cv2.resize(img, (new_w, target_h))

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ numpy
    if isinstance(left_img, Image.Image):
        left_img = np.array(left_img)

    left_resized = resize_by_height(left_img, height)
    right_resized = resize_by_height(right_img, height)

    with col1:
        st.image(left_resized, caption=captions[0])
    with col2:
        st.image(right_resized, caption=captions[1])


# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–∞–≥—Ä—É–∑–∫–∏ ---
st.markdown("#### –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–ª–∞–∑–Ω–æ–≥–æ –¥–Ω–∞ (JPG/PNG):")
uploaded_file = st.file_uploader(
    label="", type=["jpg", "jpeg", "png"], label_visibility="collapsed")

if uploaded_file:
    # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    image = Image.open(uploaded_file).convert("RGB")
    resized_image = image.resize((224, 224))
    image_tensor = transform(resized_image).to(device)

    # --- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ---
    with torch.no_grad():
        logit = model(image_tensor.unsqueeze(0))
        prob = torch.sigmoid(logit).item()
        prediction = int(prob >= 0.5)

    prob_dr = prob
    prob_healthy = 1 - prob
    pred_class = class_names[prediction]

    # --- –í—ã–≤–æ–¥ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π ---
    st.markdown(f"### ü©∫ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: **{pred_class}**")
    st.markdown(f"""
    - üü¢ **{class_names[0]}**: {prob_healthy:.4f} ({prob_healthy * 100:.2f}%)
    - üî¥ **{class_names[1]}**: {prob_dr:.4f} ({prob_dr * 100:.2f}%)
    """)

    # --- Grad-CAM ---
    if prediction == 1:
        _, cam_resized = generate_gradcam(model, image_tensor, target_class=1)
        boxed_overlay = draw_aggressive_merged_boxes(
            np.array(resized_image), cam_resized)
    else:
        boxed_overlay = np.array(resized_image)

    # --- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ---
    st.markdown("### üì∑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
    show_side_by_side(resized_image, boxed_overlay)

    # --- –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ---
    st.download_button(
        label="üì• –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∑–æ–Ω–∞–º–∏",
        data=cv2.imencode(".png", boxed_overlay)[1].tobytes(),
        file_name="gradcam_boxes.png",
        mime="image/png"
    )
