import streamlit as st
import torch
from torchvision import transforms
from PIL import Image
import cv2
import numpy as np

from utils.model import BinaryCNN
from utils.visualisation import generate_gradcam, draw_aggressive_merged_boxes

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(page_title="–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–µ—Ç–∏–Ω–æ–ø–∞—Ç–∏–∏", layout="wide")
st.title("üß† –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≥–ª–∞–∑–Ω–æ–≥–æ –¥–Ω–∞: –ó–¥–æ—Ä–æ–≤ / –î–∏–∞–±–µ—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ—Ç–∏–Ω–æ–ø–∞—Ç–∏—è")

# --- –ö–ª–∞—Å—Å—ã ---
class_names = ["–ó–¥–æ—Ä–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ", "–î–∏–∞–±–µ—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ—Ç–∏–Ω–æ–ø–∞—Ç–∏—è"]

# --- –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ---
device = torch.device(
    "mps" if torch.backends.mps.is_available() else
    "cuda" if torch.cuda.is_available() else
    "cpu"
)

# --- –ú–æ–¥–µ–ª—å ---


@st.cache_resource
def load_model():
    model = BinaryCNN()
    model.load_state_dict(torch.load("data/model1.pth", map_location=device))
    model.to(device)
    model.eval()
    return model


model = load_model()

# --- –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ ---
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# --- –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ ---
st.markdown("#### –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–ª–∞–∑–Ω–æ–≥–æ –¥–Ω–∞ (JPG/PNG):")
uploaded_file = st.file_uploader(
    label="", type=["jpg", "jpeg", "png"], label_visibility="collapsed"
)

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    resized_image = image.resize((224, 224))
    image_tensor = transform(resized_image).to(device)

    with torch.no_grad():
        logit = model(image_tensor.unsqueeze(0))
        prob = torch.sigmoid(logit).item()
        prediction = int(prob >= 0.5)

    prob_dr = prob
    prob_healthy = 1 - prob
    pred_class = class_names[prediction]

    st.markdown(f"### ü©∫ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: **{pred_class}**")
    st.markdown(f"""
    - üü¢ **{class_names[0]}**: {prob_healthy:.4f} ({prob_healthy * 100:.2f}%)
    - üî¥ **{class_names[1]}**: {prob_dr:.4f} ({prob_dr * 100:.2f}%)
    """)

    # --- Grad-CAM —Å –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞–º–∏ ---
    if prediction == 1:
        overlay, cam_resized = generate_gradcam(
            model, image_tensor, target_class=1)
        boxed_overlay = draw_aggressive_merged_boxes(
            np.array(resized_image), cam_resized)
    else:
        boxed_overlay = np.array(resized_image)

    # --- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä—è–¥–æ–º: –û—Ä–∏–≥–∏–Ω–∞–ª + –ë–æ–∫—Å—ã ---
    col1, col2 = st.columns(2)
    with col1:
        st.image(resized_image, caption="–û—Ä–∏–≥–∏–Ω–∞–ª", use_container_width=True)
    with col2:
        st.image(boxed_overlay, caption="–° –∑–æ–Ω–∞–º–∏ –≤–Ω–∏–º–∞–Ω–∏—è",
                 use_container_width=True)

    # --- –°–∫–∞—á–∏–≤–∞–Ω–∏–µ ---
    st.download_button(
        label="üì• –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∑–æ–Ω–∞–º–∏",
        data=cv2.imencode(".png", boxed_overlay)[1].tobytes(),
        file_name="gradcam_boxes.png",
        mime="image/png"
    )
